# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
from io import BytesIO
import requests
import pdfplumber
import re

# ===============================
# é¡µé¢æ ‡é¢˜åŒº
# ===============================
st.markdown("""
<div class='main-header'>
ğŸ“„ ç”µä»·è·å–ï¼ˆPDF â†’ ç”µä»·è¡¨ï¼‰
</div>
""", unsafe_allow_html=True)


# ===============================
# é¡¶éƒ¨çº¢è‰²è­¦å‘ŠåŒº
# ===============================
st.markdown("""
<div style="
    background:#FEE2E2;
    color:#991B1B;
    padding:18px 22px;
    border-left:6px solid #DC2626;
    border-radius:8px;
    font-size:16px;
    margin-bottom:25px;">
âš ï¸ <b>ä»¥ä¸‹çœä»½æš‚ä¸æ”¯æŒè‡ªåŠ¨è§£æ</b> 
 
- <b>å›½ç½‘å›¾ç‰‡æ ¼å¼</b>ï¼šæ¹–åŒ—çœã€å±±ä¸œçœã€æ²³å—çœ  

- <b>å—ç½‘æ•°æ®æ ¼å¼</b>ï¼šäº‘å—çœã€å¹¿ä¸œçœã€è´µå·çœ  

è¯·åœ¨ Page2 ä¸­æ‰‹åŠ¨ä¸Šä¼  Excel è¿›è¡ŒçŸ«æ­£ã€‚
</div>
""", unsafe_allow_html=True)



# ========================================================================
# =============== ä»¥ä¸‹éƒ¨åˆ†æ˜¯ PDF è§£æå‡½æ•°ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰ ====================
# ========================================================================

HEADERS = {
    "User-Agent": "Mozilla/5.0",
    "Referer": "https://www.95598.cn/",
    "Accept": "application/pdf",
}

def safe_float(x):
    try:
        return float(str(x).replace(",", ""))
    except:
        return None


def download_pdf_to_file(url, idx):
    resp = requests.get(url, headers=HEADERS, timeout=30)
    resp.raise_for_status()
    filename = f"power_price_{idx+1}.pdf"
    with open(filename, "wb") as f:
        f.write(resp.content)
    return filename


def detect_province_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = pdf.pages[0].extract_text() or ""

    # å»æ‰æ‰€æœ‰ç©ºç™½ï¼Œé¿å…â€œç”µåŠ›\nå…¬å¸â€è¿™ç§è¢«æ–­è¡Œçš„æƒ…å†µ
    text_clean = re.sub(r"\s+", "", text)

    start = text_clean.find("å›½ç½‘")
    if start != -1:
        end = text_clean.find("ç”µåŠ›æœ‰é™å…¬å¸", start)
        if end == -1:
            end = text_clean.find("ç”µåŠ›å…¬å¸", start)
        if end != -1:
            company = text_clean[start + len("å›½ç½‘") : end]
            province = company.strip()
        else:
            province = "æœªçŸ¥çœä»½"
    else:
        province = "æœªçŸ¥çœä»½"

    # å°ä¿®æ­£ï¼šé‡åº† â†’ é‡åº†å¸‚
    if province == "é‡åº†":
        province = "é‡åº†å¸‚"
    if province == "æœªçŸ¥çœä»½":
        province = "ä¸Šæµ·å¸‚"
    return province

# ==========================
# åŸºç¡€å°å‡½æ•°
# ==========================
def safe_float(x):
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return None

def detect_columns(df):
    """
    è¿”å›ï¼š
        period_cols: {'å°–': col_idx, 'å³°': col_idx, ...} ï¼ˆåªåŒ…å«å­˜åœ¨çš„æ¡£ä½ï¼‰
        non_time_col: éåˆ†æ—¶ç”µåº¦ç”µä»·æ‰€åœ¨åˆ—å·ï¼ˆæ‰¾ä¸åˆ°åˆ™ä¸º Noneï¼‰
    """
    period_kw_map = {
        "å°–": ["å°–å³°æ—¶æ®µ", "å°–å³°", "å°–æ—¶æ®µ", "å°–æ—¶"],
        "å³°": ["é«˜å³°æ—¶æ®µ", "é«˜å³°", "å³°æ—¶æ®µ", "å³°æ—¶"],
        "å¹³": ["å¹³æ®µ", "å¹³æ—¶æ®µ", "å¹³æ—¶"],
        "è°·": ["ä½è°·æ—¶æ®µ", "ä½è°·", "è°·æ®µ", "è°·æ—¶æ®µ", "è°·æ—¶"],
        "æ·±": ["æ·±è°·æ—¶æ®µ", "æ·±è°·", "æ·±æ—¶æ®µ", "æ·±æ—¶"],
    }

    non_time_kws = [
        "éåˆ†æ—¶ç”µåº¦ç”µä»·",
        "éåˆ†æ—¶ç”µé‡ç”µä»·",
        "éåˆ†æ—¶ç”µä»·",
    ]

    period_cols = {}
    non_time_col = None

    # âš  ä¸è¦å†æå‰ breakï¼Œæ•´å¼ è¡¨éƒ½æ‰«ä¸€éï¼Œåé¢çš„è¡Œå¯ä»¥è¦†ç›–å‰é¢çš„è¯¯åˆ¤
    for _, row in df.iterrows():
        for col_idx, cell in enumerate(row):
            s = str(cell) if cell is not None else ""

            # 1ï¼‰éåˆ†æ—¶ç”µä»·åˆ—
            if any(kw in s for kw in non_time_kws):
                non_time_col = col_idx

            # 2ï¼‰åˆ†æ—¶æ¡£ä½åˆ—
            # ğŸ”¹ å…ˆä¸“é—¨å¤„ç†â€œå°–å³°æ—¶æ®µ / å°–å³°â€ â€”â€” å¼ºåˆ¶è®¤ä¸ºåªæœ‰â€œå°–â€
            if any(w in s for w in ["å°–å³°æ—¶æ®µ", "å°–å³°"]):
                matched_shorts = ["å°–"]
            else:
                matched_shorts = []
                for short, kws in period_kw_map.items():
                    if any(kw in s for kw in kws):
                        matched_shorts.append(short)

            # åªåœ¨â€œåªå‘½ä¸­ä¸€ä¸ªæ¡£ä½â€çš„å•å…ƒæ ¼é‡Œè®¤åˆ—å·
            if len(matched_shorts) == 1:
                short = matched_shorts[0]
                period_cols[short] = col_idx
            else:
                continue
    return period_cols, non_time_col
# ---------- ä¿®å¤å››å·ï¼šæ›´ç¨³å¥åœ°è¯†åˆ«è¡¨å¤´ ----------
def get_header_time_labels(df):
    """
    åœ¨æ•´å¼ è¡¨é‡Œæ‰«æï¼Œæ‰¾åˆ°åŒ…å«åˆ†æ—¶æ¡£å…³é”®å­—çš„ä¸€è¡Œï¼Œç”¨è¿™è¡Œåˆ¤æ–­åˆ†æ—¶æ¡£ä½çš„é¡ºåºï¼Œ
    æ˜ å°„ä¸º ['å°–','å³°','å¹³','è°·','æ·±'] ä¸­çš„ä¸€éƒ¨åˆ†ã€‚
    ä¼˜å…ˆé€‰æ‹©ã€ŒåŒ…å«å°–å³°ã€çš„è¡Œï¼Œè‹¥æ²¡æœ‰å†é€€è€Œæ±‚å…¶æ¬¡ã€‚
    """
    raw_to_short = {
        # å°– / å°–å³°
        "å°–å³°æ—¶æ®µ": "å°–", "å°–å³°": "å°–", "å°–æ—¶æ®µ": "å°–", "å°–æ—¶": "å°–", "å°–": "å°–",
        # å³°ï¼ˆé«˜å³°ã€å³°æ®µã€å³°æ—¶ç­‰ï¼‰
        "é«˜å³°æ—¶æ®µ": "å³°", "é«˜å³°": "å³°", "å³°æ®µ": "å³°",
        "å³°æ—¶æ®µ": "å³°", "å³°æ—¶": "å³°", "å³°": "å³°",
        # å¹³
        "å¹³æ®µ": "å¹³", "å¹³æ—¶æ®µ": "å¹³", "å¹³æ—¶": "å¹³", "å¹³": "å¹³",
        # è°·
        "ä½è°·æ—¶æ®µ": "è°·", "ä½è°·": "è°·", "è°·æ®µ": "è°·",
        "è°·æ—¶æ®µ": "è°·", "è°·æ—¶": "è°·", "è°·": "è°·",
        # æ·±è°· / æ·±
        "æ·±è°·æ—¶æ®µ": "æ·±", "æ·±è°·": "æ·±", "æ·±æ—¶æ®µ": "æ·±", "æ·±æ—¶": "æ·±", "æ·±": "æ·±",
    }

    # ---------- ç¬¬ 1 è½®ï¼šä¼˜å…ˆæ‰¾åŒ…å«â€œå°–å³°â€çš„è¡¨å¤´è¡Œ ----------
    header_text = ""
    # ä¼˜å…ˆæ‰¾åŒ…å«â€œå°–å³°â€çš„è¡Œ
    for _, row in df.iterrows():
        row_text = "".join(str(c) for c in row)
        if "å°–å³°" in row_text:
            hits = set()
            for raw in raw_to_short.keys():
                if raw in row_text:
                    hits.add(raw_to_short[raw])
            if len(hits) >= 2:
                header_text = row_text
                break

    # ---------- ç¬¬ 2 è½®ï¼šå¦‚æœæ²¡æœ‰å°–å³°ï¼Œå†é€€è€Œæ±‚å…¶æ¬¡ ----------
    if not header_text:
        # å†æ‰¾ä»»æ„åŒ…å«ä¸¤ä¸ªä»¥ä¸Šæ—¶æ®µå…³é”®å­—çš„è¡Œ
        for _, row in df.iterrows():
            row_text = "".join(str(c) for c in row)
            hits = set()
            for raw in raw_to_short.keys():
                if raw in row_text:
                    hits.add(raw_to_short[raw])
            if len(hits) >= 2:
                header_text = row_text
                break

    if not header_text:
        # æ²¡è¯†åˆ«åˆ°ï¼Œè¯´æ˜è¿™ä¸ªçœå¯èƒ½å®Œå…¨æ²¡æœ‰åˆ†æ—¶ç”µä»·
        return []

    positions = []
    for raw, short in raw_to_short.items():
        idx = header_text.find(raw)
        if idx != -1:
            positions.append((idx, short))

    positions.sort(key=lambda x: x[0])

    ordered = []
    for _, short in positions:
        if short not in ordered:
            ordered.append(short)

    return ordered

def get_time_cluster_from_row(row):
    values = list(row)
    cluster_rev = []
    started = False
    count = 0

    # ä»å³å‘å·¦ï¼Œæœ€å¤šæŠ“ 5 ä¸ªâ€œåƒç”µä»·çš„æ•°å­—â€
    for cell in reversed(values):
        v = safe_float(cell)
        if v is not None and 0.05 <= v <= 10:
            if not started:
                started = True
            if count < 5:
                cluster_rev.append(v)
                count += 1
            else:
                break
        else:
            if started:
                break
            else:
                continue

    return list(reversed(cluster_rev))

def map_cluster_to_periods(cluster, period_order):
    """
    å°†åˆ†æ—¶ç”µä»·ç°‡ï¼ˆclusterï¼‰å³å¯¹é½æ˜ å°„åˆ° period_order é‡Œã€‚
    è¿”å›ï¼š{'å°–':None,'å³°':x,'å¹³':y,'è°·':z,'æ·±':None}
    """
    result = {p: None for p in ["å°–", "å³°", "å¹³", "è°·", "æ·±"]}
    if not period_order or not cluster:
        return result

    n = len(period_order)
    m = len(cluster)

    if m == n:
        # 1 å¯¹ 1 å¯¹é½
        for i, p in enumerate(period_order):
            result[p] = cluster[i]
    else:
        # é»˜è®¤å³å¯¹é½ï¼ˆç¼ºå°–æ—¶ï¼‰ï¼Œå…¼å®¹ç¦å»ºè¿™ç±»æƒ…å†µ
        offset = n - m
        for i, p in enumerate(period_order):
            j = i - offset
            if 0 <= j < m:
                result[p] = cluster[j]

    return result


def extract_row_prices(row, period_order):
    """
    ä»ä¸€è¡Œä¸­æŠ½å–ï¼šéåˆ†æ—¶ç”µä»· + åˆ†æ—¶ç”µä»·ï¼ˆæŒ‰ period_order æ˜ å°„ï¼‰
    """
    # éåˆ†æ—¶ç”µä»· = è¿™ä¸€è¡Œç¬¬ä¸€ä¸ª 0.1~2 ä¹‹é—´çš„æ•°
    non_time = None
    for cell in row:
        v = safe_float(cell)
        if v is not None and 0.1 <= v <= 2:
            non_time = v
            break

    cluster = get_time_cluster_from_row(row)
    period_vals = map_cluster_to_periods(cluster, period_order)

    result = {"non_time": non_time}
    result.update(period_vals)
    return result

# ---------- ä¿®å¤ä¸Šæµ·ï¼šæ›´é€šç”¨çš„ç”µå‹åŒ¹é… ----------
def find_voltage_rows_1_10kv(df):
    """
    åœ¨æ•´å¼ è¡¨ä¸­æ‰¾åˆ°â€œ1-10ï¼ˆ20ï¼‰åƒä¼ / 1-10åƒä¼ / 10åƒä¼â€ç­‰è¡Œã€‚
    ä¼˜å…ˆåŒ¹é… 1-10ï¼ˆ20ï¼‰åƒä¼ï¼Œå¦‚æœæ²¡æœ‰ï¼Œå†åŒ¹é… 10åƒä¼ã€‚
    """
    # 1) å…ˆæ‰¾ 1-10ï¼ˆ20ï¼‰åƒä¼ / 1-10åƒä¼ / 1~10åƒä¼
    pattern_1_10 = re.compile(
        r"1\s*[-~ï½è‡³åˆ°]\s*10(?:ï¼ˆ\s*20\s*ï¼‰|\(\s*20\s*\))?\s*(åƒä¼|kV|KV)"
    )
    idxs = []
    for i, row in df.iterrows():
        text = "".join(str(c) for c in row.values)
        if pattern_1_10.search(text):
            idxs.append(i)

    if idxs:
        return idxs

    # 2) å¦‚æœå®Œå…¨æ²¡æœ‰ 1-10 è¿™ç§å†™æ³•ï¼Œé€€åŒ–ä¸ºæ‰¾ â€œ10åƒä¼â€
    pattern_10kv = re.compile(r"(^|[^0-9])10\s*åƒä¼(?!å®‰)")
    idxs = []
    for i, row in df.iterrows():
        text = "".join(str(c) for c in row.values)
        if pattern_10kv.search(text):
            idxs.append(i)

    return idxs
def extract_row_prices_fallback(row, period_order):
    # éåˆ†æ—¶ç”µä»·ï¼šè¿™ä¸€è¡Œç¬¬ä¸€ä¸ª 0.1~2 çš„æ•°å­—
    non_time = None
    for cell in row:
        v = safe_float(cell)
        if v is not None and 0.1 <= v <= 2:
            non_time = v
            break

    cluster = get_time_cluster_from_row(row)
    period_vals = map_cluster_to_periods(cluster, period_order)

    result = {"non_time": non_time}
    result.update(period_vals)
    return result

# ==========================
# è§£æå•ä¸ª PDF â†’ è¿”å›è¯¥çœçš„ 1-10kV ç»“æœ
# ==========================
def parse_single_pdf(pdf_path):
    province = detect_province_from_pdf(pdf_path)
    city = ""  # ç›®å‰å›½ç½‘è¡¨é‡Œæ²¡æœ‰åŸå¸‚è¿™ä¸€å±‚ï¼Œå°±å…ˆç•™ç©º

    # 1. PDF â†’ DataFrame
    rows = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            for table in page.extract_tables():
                for row in table:
                    clean = [c.strip() if isinstance(c, str) else c for c in row]
                    if any(clean):
                        rows.append(clean)

    if not rows:
        print(f"[{province}] æ²¡æœ‰è§£æåˆ°ä»»ä½•è¡¨æ ¼ã€‚")
        return pd.DataFrame()

    df = pd.DataFrame(rows)
    df.replace("", None, inplace=True)
    df.dropna(how="all", axis=1, inplace=True)
    df.dropna(how="all", axis=0, inplace=True)
    df.reset_index(drop=True, inplace=True)

    # 2. è¯†åˆ«åˆ†æ—¶æ¡£é¡ºåº
    period_cols, non_time_col = detect_columns(df)
    print(f"[{province}] æ£€æµ‹åˆ°åˆ—ï¼š", period_cols, " éåˆ†æ—¶åˆ— =", non_time_col)


    voltage_label = "1-10ï¼ˆ20ï¼‰åƒä¼"  # åªæ˜¯æœ€ç»ˆè¾“å‡ºçš„å±•ç¤ºæ–‡å­—
    row_indices = find_voltage_rows_1_10kv(df)

    if not row_indices:
        print(f"[{province}] æœªæ‰¾åˆ° 1-10ï¼ˆ20ï¼‰åƒä¼ / 10åƒä¼ è¡Œï¼Œè·³è¿‡ã€‚")
        return pd.DataFrame()

    if "æµ™æ±Ÿ" in province:
        # æµ™æ±Ÿå–ç¬¬ 2ã€3 æ¡
        if len(row_indices) >= 3:
            row_indices = row_indices[1:3]
        else:
            row_indices = row_indices[:2]

    elif "æ±Ÿè‹" in province:
        # æ±Ÿè‹ PDF é‡Œæ˜¯ å…ˆä¸¤éƒ¨åˆ¶ åå•ä¸€åˆ¶ï¼Œéœ€è¦åè¿‡æ¥
        row_indices = row_indices[:2]
        if len(row_indices) == 2:
            row_indices = [row_indices[1], row_indices[0]]

    else:
        # å…¶ä»–çœä»½ï¼šé»˜è®¤å–å‰ä¸¤æ¡ï¼ˆå•ä¸€åˆ¶ + ä¸¤éƒ¨åˆ¶ï¼‰
        row_indices = row_indices[:2]
    rows_out = []

    for pos, idx in enumerate(row_indices):
        row = df.iloc[idx]

        # 5. è¯»å–ä»·æ ¼ï¼ˆä½ åŸæ¥çš„é€»è¾‘ï¼‰
        if period_cols:
            price_info = {"non_time": None, "å°–": None, "å³°": None, "å¹³": None, "è°·": None, "æ·±": None}

            # éåˆ†æ—¶ç”µä»·
            if non_time_col is not None and non_time_col < len(row):
                price_info["non_time"] = safe_float(row[non_time_col])
            # å…œåº•å†æ‰«ä¸€é
            if price_info["non_time"] is None:
                for cell in row:
                    v = safe_float(cell)
                    if v is not None and 0.1 <= v <= 2:
                        price_info["non_time"] = v
                        break

            # å„åˆ†æ—¶æ®µ
            for p, col_idx in period_cols.items():
                if col_idx < len(row):
                    price_info[p] = safe_float(row[col_idx])

        else:
            period_order = get_header_time_labels(df)
            price_info = extract_row_prices_fallback(row, period_order)

        # ------------------------------------------------------------------
        # ã€æ–°å¢ã€‘æµ™æ±Ÿçœä¸“ç”¨ä¿®æ­£ï¼šå»æ‰â€œæ”¿åºœæ€§åŸºé‡‘â€é‚£ä¸€åˆ—ï¼Œåªä¿ç•™ å°–/å³°/å¹³/è°·
        # ------------------------------------------------------------------
        if "æµ™æ±Ÿ" in province:
            cluster = get_time_cluster_from_row(row)  # ä¾‹å¦‚ [0.0292, 1.3162, 1.0969, 0.6648, 0.2526]

            # å¦‚æœå‰é¢æœ‰ä¸€ä¸ªå¾ˆå°çš„æ•°ï¼ˆé€šå¸¸æ˜¯æ”¿åºœæ€§åŸºé‡‘ï¼‰ï¼ŒæŠŠå®ƒä¸¢æ‰ï¼Œåªä¿ç•™å 4 ä¸ª
            while len(cluster) > 4 and cluster[0] is not None and cluster[0] < 0.1:
                cluster = cluster[1:]

            if len(cluster) == 4:
                # ä¿ç•™åŸæ¥ç®—å‡ºæ¥çš„ non_timeï¼ˆä¸åˆ†æ—¶ç”µä»·ï¼‰
                non_time_val = price_info.get("non_time")

                price_info = {
                    "non_time": non_time_val,
                    "å°–": cluster[0],
                    "å³°": cluster[1],
                    "å¹³": cluster[2],
                    "è°·": cluster[3],
                    "æ·±": None,  # æµ™æ±Ÿæ²¡æœ‰æ·±è°·
                }
        # ------------------------------------------------------------------

        # 6. è¡Œæ ‡ç­¾ï¼šå•ä¸€åˆ¶ / ä¸¤éƒ¨åˆ¶ / æ–¹æ¡ˆ3...
        if pos == 0:
            scheme = "å•ä¸€åˆ¶"
        elif pos == 1:
            scheme = "ä¸¤éƒ¨åˆ¶"
        else:
            scheme = f"æ–¹æ¡ˆ{pos + 1}"

        rows_out.append(
            {
                "çœä»½": province,
                "åŸå¸‚": city if province != "é‡åº†å¸‚" else "é‡åº†å¸‚",
                "åˆ¶åº¦": scheme,
                "ç”µå‹ç­‰çº§": voltage_label,
                "ä¸åˆ†æ—¶ç”µä»·": price_info["non_time"],
                "å°–": price_info["å°–"],
                "å³°": price_info["å³°"],
                "å¹³": price_info["å¹³"],
                "è°·": price_info["è°·"],
                "æ·±": price_info["æ·±"],
            }
        )

    return pd.DataFrame(rows_out)

def parse_price_from_urls(url_list):
    results = []
    errors = []

    for i, url in enumerate(url_list):
        try:
            file = download_pdf_to_file(url, i)
            df_one = parse_single_pdf(file)
            if df_one.empty:
                errors.append((url, "æœªèƒ½è¯†åˆ«æœ‰æ•ˆç”µä»·è¡Œ"))
            else:
                results.append(df_one)

        except Exception as e:
            errors.append((url, str(e)))

    if results:
        df_final = pd.concat(results, ignore_index=True)
    else:
        df_final = pd.DataFrame()

    return df_final, errors
# ========================================================================
# =============================== UI éƒ¨åˆ† ================================
# ========================================================================


# è¾“å…¥åŒºå¡ç‰‡
st.markdown("<div class='card'>", unsafe_allow_html=True)

st.markdown("""
<div class='card-title'>
    <div class='icon-circle'>ğŸ”—</div>
    è¾“å…¥ PDF é“¾æ¥
</div>
""", unsafe_allow_html=True)

url_text = st.text_area(
    "æ¯è¡Œä¸€ä¸ª PDF é“¾æ¥",
    height=200,
    placeholder="https://www.95598.cn/...pdf\nhttps://www.95598.cn/...pdf"
)


if st.button("â–¶ è§£æç”µä»·", use_container_width=True):

    urls = [u
            for u in url_text.splitlines()
            if u.strip()]

    if not urls:
        st.error("âŒ è¯·è‡³å°‘ç²˜è´´ä¸€ä¸ªé“¾æ¥")
        st.stop()

    df_price, errors = parse_price_from_urls(urls)

    st.session_state["price_raw"] = df_price

    st.markdown("</div>", unsafe_allow_html=True)

    # è¾“å‡ºå¡ç‰‡
    st.markdown("<div class='card'>", unsafe_allow_html=True)
    st.markdown("""
    <div class='card-title'>
        <div class='icon-circle'>ğŸ“Š</div>
        è§£æç»“æœ
    </div>
    """, unsafe_allow_html=True)

    if df_price is not None and not df_price.empty:
        st.success(f"è§£æå®Œæˆï¼šå…± {len(df_price)} æ¡è®°å½•")
        st.dataframe(df_price)

        buf = BytesIO()
        df_price.to_excel(buf, index=False)
        st.download_button(
            "ğŸ“¥ ä¸‹è½½ç”µä»·è¡¨ï¼ˆExcelï¼‰",
            buf.getvalue(),
            "ç”µä»·è§£æç»“æœ.xlsx",
            mime="application/vnd.ms-excel",
            use_container_width=True
        )
    else:
        st.warning("âš  æœªèƒ½è§£æä»»ä½•ç”µä»·")

    st.markdown("</div>", unsafe_allow_html=True)

    # é”™è¯¯å¡ç‰‡
    if errors:
        st.markdown("<div class='card'>", unsafe_allow_html=True)
        st.markdown("""
        <div class='card-title'>
            <div class='icon-circle'>âš ï¸</div>
            è§£æå¤±è´¥åˆ—è¡¨
        </div>
        """, unsafe_allow_html=True)
        err_df = pd.DataFrame(errors, columns=["URL", "é”™è¯¯ä¿¡æ¯"])
        st.dataframe(err_df)
        st.markdown("</div>", unsafe_allow_html=True)

else:
    st.markdown("</div>", unsafe_allow_html=True)
