# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import re
from io import BytesIO

import requests
import pdfplumber

# ===============================
# é¡µé¢é…ç½® + CSS
# ===============================
st.set_page_config(page_title="å²šå›¾è¶…å……ç«™ç”µè´¹è‡ªåŠ¨è®¡ç®—ç³»ç»Ÿ", layout="wide")

st.markdown("""
<style>
    body {
        background-color:#f3f4f6;
    }
    .main-title {
        font-size:38px !important;
        color:white;
        text-align:center;
        padding:22px;
        background:linear-gradient(90deg,#1D4ED8,#0EA5E9);
        border-radius:14px;
        margin-bottom:25px;
        font-weight:700;
    }
    .sub-title {
        font-size:18px;
        color:#374151;
        margin-bottom:18px;
        text-align:center;
    }
    .card {
        background:white;
        padding:20px 24px;
        border-radius:14px;
        box-shadow:0 8px 24px rgba(15,23,42,0.08);
        margin-bottom:24px;
        border:1px solid #e5e7eb;
    }
    .section-title {
        font-size:20px;
        font-weight:600;
        color:#111827;
        margin-bottom:12px;
        display:flex;
        align-items:center;
        gap:8px;
    }
    .section-title span.icon {
        width:26px;
        height:26px;
        border-radius:999px;
        display:inline-flex;
        align-items:center;
        justify-content:center;
        background:#EFF6FF;
        color:#1D4ED8;
        font-size:16px;
    }
</style>
""", unsafe_allow_html=True)

# ===============================
# ---------- å…¬å…±å·¥å…·å‡½æ•° ----------
# ===============================

def parse_time_rule_line(line):
    line = line.strip()
    if re.match(r"^\d{1,2}:\d{2}", line):
        return "", line
    parts = line.split(" ", 1)
    if len(parts) == 1:
        return parts[0], ""
    return parts[0], parts[1].strip()

def parse_month_rule(text):
    if pd.isna(text):
        return []
    lines = [l for l in str(text).split("\n") if l.strip()]
    out = []
    for l in lines:
        t, tm = parse_time_rule_line(l)
        out.append({"type": t, "time": tm})
    return out

def get_price(tier, row):
    if tier == "":
        return row.get("ä¸åˆ†æ—¶ç”µä»·", None)
    return row.get(tier, None)

# ===============================
# 1ï¼‰è¶…å……ç«™ç”µè´¹è®¡ç®—æ ¸å¿ƒå‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
# ===============================

def process_station_prices(df_station, df_price, month):
    df_station = df_station.copy()
    df_station["é…ç½®"] = df_station["é…ç½®"].astype(str).str.strip()
    df_station = df_station[df_station["é…ç½®"] != "å…¶ä»–"]

    output = []
    errors = []
    col = f"ç”µè´¹-{month}æœˆ"

    for _, r in df_station.iterrows():
        prov = r["æ‰€åœ¨çœä»½"]
        city = r["æ‰€å±å¸‚åŒº"]
        config = str(r["é…ç½®"]).strip()
        fs = str(r["æ˜¯å¦åˆ†æ—¶"]).strip()
        mult = float(r["ç”µè´¹ä¹˜å­"])
        rule_txt = r.get(col, "")

        match = df_price[(df_price["çœä»½"] == prov) &
                         (df_price["åˆ¶åº¦"] == config)]

        if match.empty:
            final = "æœªåŒ¹é…åˆ°ä»·æ ¼"
            errors.append((r["åºå·"], r["ç«™ç‚¹åç§°"], prov, city, config))
        else:
            prow = match.iloc[0]

            if fs == "å¦":
                p = prow["ä¸åˆ†æ—¶ç”µä»·"] * mult
                final = f"0:00 - 24:00 {round(p,4)}å…ƒ/åº¦"
            else:
                rules = parse_month_rule(rule_txt)
                lines = []
                for rr in rules:
                    t = rr["type"]
                    tm = rr["time"]
                    base = get_price(t, prow)
                    if base is None:
                        lines.append(f"{t} {tm} æ— å¯¹åº”ç”µä»·")
                    else:
                        p = round(base * mult, 4)
                        if t == "":
                            lines.append(f"{tm} {p}å…ƒ/åº¦")
                        else:
                            lines.append(f"{t} {tm} {p}å…ƒ/åº¦")
                final = "\n".join(lines)

        output.append({
            "åºå·": r["åºå·"],
            "ç«™ç‚¹åç§°": r["ç«™ç‚¹åç§°"],
            "çœä»½": prov,
            "åŸå¸‚": city,
            "é…ç½®": config,
            "æ˜¯å¦åˆ†æ—¶": fs,
            "ç”µè´¹ä¹˜å­": mult,
            "ç”µè´¹": final
        })

    return pd.DataFrame(output), errors

# ===============================
# 2ï¼‰ç”µä»· PDF â†’ ç”µä»·è¡¨ çš„æ‰€æœ‰å‡½æ•°ï¼ˆä¸ä½ è„šæœ¬ä¸€è‡´ï¼‰
# ===============================

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/122.0.0.0 Safari/537.36",
    "Referer": "https://www.95598.cn/",
    "Accept": "application/pdf,application/octet-stream",
}

def safe_float(x):
    try:
        return float(str(x).replace(",", ""))
    except Exception:
        return None

def download_pdf_to_file(url, idx):
    resp = requests.get(url, headers=HEADERS, timeout=30)
    resp.raise_for_status()
    filename = f"power_price_{idx+1}.pdf"
    with open(filename, "wb") as f:
        f.write(resp.content)
    return filename

def detect_province_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = pdf.pages[0].extract_text() or ""
    text_clean = re.sub(r"\s+", "", text)
    start = text_clean.find("å›½ç½‘")
    if start != -1:
        end = text_clean.find("ç”µåŠ›æœ‰é™å…¬å¸", start)
        if end == -1:
            end = text_clean.find("ç”µåŠ›å…¬å¸", start)
        if end != -1:
            company = text_clean[start + len("å›½ç½‘"): end]
            province = company.strip()
        else:
            province = "æœªçŸ¥çœä»½"
    else:
        province = "æœªçŸ¥çœä»½"
    if province == "é‡åº†":
        province = "é‡åº†å¸‚"
    if province == "æœªçŸ¥çœä»½":
        province = "ä¸Šæµ·å¸‚"
    return province

def detect_columns(df):
    period_kw_map = {
        "å°–": ["å°–å³°æ—¶æ®µ", "å°–å³°", "å°–æ—¶æ®µ", "å°–æ—¶"],
        "å³°": ["é«˜å³°æ—¶æ®µ", "é«˜å³°", "å³°æ—¶æ®µ", "å³°æ—¶"],
        "å¹³": ["å¹³æ®µ", "å¹³æ—¶æ®µ", "å¹³æ—¶"],
        "è°·": ["ä½è°·æ—¶æ®µ", "ä½è°·", "è°·æ®µ", "è°·æ—¶æ®µ", "è°·æ—¶"],
        "æ·±": ["æ·±è°·æ—¶æ®µ", "æ·±è°·", "æ·±æ—¶æ®µ", "æ·±æ—¶"],
    }
    non_time_kws = [
        "éåˆ†æ—¶ç”µåº¦ç”µä»·",
        "éåˆ†æ—¶ç”µé‡ç”µä»·",
        "éåˆ†æ—¶ç”µä»·",
    ]
    period_cols = {}
    non_time_col = None
    for _, row in df.iterrows():
        for col_idx, cell in enumerate(row):
            s = str(cell) if cell is not None else ""
            if any(kw in s for kw in non_time_kws):
                non_time_col = col_idx
            if any(w in s for w in ["å°–å³°æ—¶æ®µ", "å°–å³°"]):
                matched_shorts = ["å°–"]
            else:
                matched_shorts = []
                for short, kws in period_kw_map.items():
                    if any(kw in s for kw in kws):
                        matched_shorts.append(short)
            if len(matched_shorts) == 1:
                short = matched_shorts[0]
                period_cols[short] = col_idx
    return period_cols, non_time_col

def get_header_time_labels(df):
    raw_to_short = {
        "å°–å³°æ—¶æ®µ": "å°–", "å°–å³°": "å°–", "å°–æ—¶æ®µ": "å°–", "å°–æ—¶": "å°–", "å°–": "å°–",
        "é«˜å³°æ—¶æ®µ": "å³°", "é«˜å³°": "å³°", "å³°æ®µ": "å³°",
        "å³°æ—¶æ®µ": "å³°", "å³°æ—¶": "å³°", "å³°": "å³°",
        "å¹³æ®µ": "å¹³", "å¹³æ—¶æ®µ": "å¹³", "å¹³æ—¶": "å¹³", "å¹³": "å¹³",
        "ä½è°·æ—¶æ®µ": "è°·", "ä½è°·": "è°·", "è°·æ®µ": "è°·",
        "è°·æ—¶æ®µ": "è°·", "è°·æ—¶": "è°·", "è°·": "è°·",
        "æ·±è°·æ—¶æ®µ": "æ·±", "æ·±è°·": "æ·±", "æ·±æ—¶æ®µ": "æ·±", "æ·±æ—¶": "æ·±", "æ·±": "æ·±",
    }
    header_text = ""
    for _, row in df.iterrows():
        row_text = "".join(str(c) for c in row)
        if "å°–å³°" in row_text:
            hits = set()
            for raw in raw_to_short.keys():
                if raw in row_text:
                    hits.add(raw_to_short[raw])
            if len(hits) >= 2:
                header_text = row_text
                break
    if not header_text:
        for _, row in df.iterrows():
            row_text = "".join(str(c) for c in row)
            hits = set()
            for raw in raw_to_short.keys():
                if raw in row_text:
                    hits.add(raw_to_short[raw])
            if len(hits) >= 2:
                header_text = row_text
                break
    if not header_text:
        return []
    positions = []
    for raw, short in raw_to_short.items():
        idx = header_text.find(raw)
        if idx != -1:
            positions.append((idx, short))
    positions.sort(key=lambda x: x[0])
    ordered = []
    for _, short in positions:
        if short not in ordered:
            ordered.append(short)
    return ordered

def get_time_cluster_from_row(row):
    values = list(row)
    cluster_rev = []
    started = False
    count = 0
    for cell in reversed(values):
        v = safe_float(cell)
        if v is not None and 0.05 <= v <= 10:
            if not started:
                started = True
            if count < 5:
                cluster_rev.append(v)
                count += 1
            else:
                break
        else:
            if started:
                break
            else:
                continue
    return list(reversed(cluster_rev))

def map_cluster_to_periods(cluster, period_order):
    result = {p: None for p in ["å°–", "å³°", "å¹³", "è°·", "æ·±"]}
    if not period_order or not cluster:
        return result
    n = len(period_order)
    m = len(cluster)
    if m == n:
        for i, p in enumerate(period_order):
            result[p] = cluster[i]
    else:
        offset = n - m
        for i, p in enumerate(period_order):
            j = i - offset
            if 0 <= j < m:
                result[p] = cluster[j]
    return result

def extract_row_prices_with_cluster(row, period_order, non_time_col=None):
    non_time = None
    if non_time_col is not None and non_time_col < len(row):
        non_time = safe_float(row[non_time_col])
    if non_time is None:
        for cell in row:
            v = safe_float(cell)
            if v is not None and 0.1 <= v <= 2:
                non_time = v
                break
    cluster = get_time_cluster_from_row(row)
    period_vals = map_cluster_to_periods(cluster, period_order)
    result = {"non_time": non_time}
    result.update(period_vals)
    return result

def find_voltage_rows_1_10kv(df):
    pattern_1_10 = re.compile(
        r"1\s*[-~ï½è‡³åˆ°]\s*10(?:ï¼ˆ\s*20\s*ï¼‰|\(\s*20\s*\))?\s*(åƒä¼|kV|KV)"
    )
    idxs = []
    for i, row in df.iterrows():
        text = "".join(str(c) for c in row.values)
        if pattern_1_10.search(text):
            idxs.append(i)
    if idxs:
        return idxs
    pattern_10kv = re.compile(r"(^|[^0-9])10\s*åƒä¼(?!å®‰)")
    idxs = []
    for i, row in df.iterrows():
        text = "".join(str(c) for c in row.values)
        if pattern_10kv.search(text):
            idxs.append(i)
    return idxs

def parse_single_pdf(pdf_path):
    province = detect_province_from_pdf(pdf_path)

    rows = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            for table in page.extract_tables():
                for row in table:
                    clean = [c.strip() if isinstance(c, str) else c for c in row]
                    if any(clean):
                        rows.append(clean)
    if not rows:
        return pd.DataFrame()

    df = pd.DataFrame(rows)
    df.replace("", None, inplace=True)
    df.dropna(how="all", axis=1, inplace=True)
    df.dropna(how="all", axis=0, inplace=True)
    df.reset_index(drop=True, inplace=True)

    period_cols, non_time_col = detect_columns(df)   # non_time_col ä¸»è¦ç”¨æ¥é”â€œéåˆ†æ—¶ç”µä»·â€é‚£ä¸€åˆ—
    period_order = get_header_time_labels(df)

    voltage_label = "1-10ï¼ˆ20ï¼‰åƒä¼"
    row_indices = find_voltage_rows_1_10kv(df)
    if not row_indices:
        return pd.DataFrame()

    if "æµ™æ±Ÿ" in province:
        if len(row_indices) >= 3:
            row_indices = row_indices[1:3]
        else:
            row_indices = row_indices[:2]
    elif "æ±Ÿè‹" in province:
        row_indices = row_indices[:2]
        if len(row_indices) == 2:
            row_indices = [row_indices[1], row_indices[0]]
    else:
        row_indices = row_indices[:2]

    rows_out = []
    for pos, idx in enumerate(row_indices):
        row = df.iloc[idx]
        price_info = extract_row_prices_with_cluster(
            row, period_order=period_order, non_time_col=non_time_col
        )
        if pos == 0:
            scheme = "å•ä¸€åˆ¶"
        elif pos == 1:
            scheme = "ä¸¤éƒ¨åˆ¶"
        else:
            scheme = f"æ–¹æ¡ˆ{pos + 1}"
        city = province if province.endswith("å¸‚") else ""
        rows_out.append(
            {
                "çœä»½": province,
                "åŸå¸‚": city,
                "åˆ¶åº¦": scheme,
                "ç”µå‹ç­‰çº§": voltage_label,
                "ä¸åˆ†æ—¶ç”µä»·": price_info["non_time"],
                "å°–": price_info["å°–"],
                "å³°": price_info["å³°"],
                "å¹³": price_info["å¹³"],
                "è°·": price_info["è°·"],
                "æ·±": price_info["æ·±"],
            }
        )
    return pd.DataFrame(rows_out)

def parse_price_from_urls(url_list):
    """è¾“å…¥å¤šä¸ª PDF é“¾æ¥ï¼Œè¿”å›æ‹¼å¥½çš„ç”µä»·è¡¨ + é”™è¯¯ä¿¡æ¯åˆ—è¡¨"""
    all_results = []
    errors = []
    for i, url in enumerate(url_list):
        if not url:
            continue
        try:
            filename = download_pdf_to_file(url, i)
            df_one = parse_single_pdf(filename)
            if not df_one.empty:
                all_results.append(df_one)
            else:
                errors.append((url, "æœªæå–åˆ°ç”µä»·è¡Œ"))
        except Exception as e:
            errors.append((url, str(e)))
    if all_results:
        final_df = pd.concat(all_results, ignore_index=True)
    else:
        final_df = pd.DataFrame()
    return final_df, errors

# ===============================
# é¡µé¢æ ‡é¢˜
# ===============================
st.markdown('<div class="main-title">å²šå›¾è¶…å……ç«™ç”µè´¹è‡ªåŠ¨è®¡ç®—ç³»ç»Ÿ</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">â‘  ç”µä»·è·å–ï¼ˆPDFâ†’Excelï¼‰ â‘¡ è¶…å……ç«™ç”µè´¹è®¾ç½®ï¼ˆExcelâ†’ç»“æœï¼‰</div>', unsafe_allow_html=True)

# ===============================
# ä¸¤ä¸ªä¸»åŠŸèƒ½ï¼šç”¨ Tab åˆ†å¼€
# ===============================
tab1, tab2 = st.tabs(["âš¡ 1. ç”µä»·è·å–ï¼ˆPDF â†’ ç”µä»·è¡¨ï¼‰", "ğŸ­ 2. è¶…å……ç«™ç”µè´¹è®¾ç½®"])

# -------------------------------------------------------------------
# Tab1ï¼šç”µä»·è·å–
# -------------------------------------------------------------------
with tab1:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown('<div class="section-title"><span class="icon">âš¡</span>ç”µä»· PDF é“¾æ¥è§£æ</div>', unsafe_allow_html=True)
    st.write("åœ¨ä¸‹é¢çš„æ–‡æœ¬æ¡†ä¸­ï¼Œæ¯è¡Œç²˜è´´ä¸€ä¸ªå›½ç½‘ PDF ç”µä»·é“¾æ¥ï¼Œç‚¹å‡» **è§£æç”µä»·** å³å¯å¾—åˆ°æ ‡å‡†åŒ–çš„ç”µä»·è¡¨ï¼Œå¹¶å¯ä¸‹è½½ä¸º Excelã€‚")

    url_text = st.text_area("åœ¨æ­¤ç²˜è´´ PDF é“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", height=180,
                            placeholder="https://www.95598.cn/omg-static/....pdf\nhttps://www.95598.cn/omg-static/....pdf")

    btn_parse = st.button("â–¶ è§£æç”µä»·", key="btn_parse_price")

    if btn_parse:
        urls = [u.strip() for u in url_text.splitlines() if u.strip()]
        if not urls:
            st.error("âŒ è¯·è‡³å°‘ç²˜è´´ä¸€ä¸ª PDF é“¾æ¥ã€‚")
        else:
            with st.spinner("æ­£åœ¨ä¸‹è½½å¹¶è§£æ PDF ç”µä»·è¡¨..."):
                df_price, pdf_errs = parse_price_from_urls(urls)

            if df_price is None or df_price.empty:
                st.error("âš  æœªè§£æå‡ºä»»ä½•ç”µä»·è®°å½•ï¼Œè¯·æ£€æŸ¥é“¾æ¥æˆ– PDF å†…å®¹ã€‚")
            else:
                st.success(f"âœ… è§£ææˆåŠŸï¼Œå…±å¾—åˆ° {len(df_price)} æ¡ç”µä»·è®°å½•ã€‚")
                st.dataframe(df_price)

                # ä¸‹è½½ç”µä»·è¡¨
                buf_price = BytesIO()
                df_price.to_excel(buf_price, index=False)
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½ç”µä»·è¡¨ Excelï¼ˆå¯ç”¨äº Tab2ï¼‰",
                    buf_price.getvalue(),
                    file_name="ç”µä»·è§£æç»“æœ_1-10kV_å…¨éƒ¨çœä»½.xlsx",
                    mime="application/vnd.ms-excel"
                )

            # æ˜¾ç¤ºè§£æé”™è¯¯
            if pdf_errs:
                st.markdown("----")
                st.markdown("**âš  ä»¥ä¸‹é“¾æ¥è§£æå¤±è´¥æˆ–æœªè·å–åˆ°æœ‰æ•ˆç”µä»·ï¼š**")
                err_df = pd.DataFrame(pdf_errs, columns=["URL", "é”™è¯¯ä¿¡æ¯"])
                st.dataframe(err_df)
    st.markdown('</div>', unsafe_allow_html=True)

# -------------------------------------------------------------------
# Tab2ï¼šè¶…å……ç«™ç”µè´¹è®¾ç½®
# -------------------------------------------------------------------
with tab2:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown('<div class="section-title"><span class="icon">ğŸ­</span>è¶…å……ç«™ç”µè´¹è®¡ç®—</div>', unsafe_allow_html=True)
    st.write("ä¸Šä¼  **ç«™ç‚¹ä¿¡æ¯ Excel** å’Œ **ç”µä»·è¡¨ Excel**ï¼Œé€‰æ‹©æœˆä»½åç‚¹å‡»å¼€å§‹è®¡ç®—ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆå„ç«™ç‚¹åˆ†æ—¶ç”µä»·è®¾ç½®ã€‚")
    st.info("ğŸ’¡ ç”µä»·è¡¨ Excel åˆ—åéœ€åŒ…å«ï¼š`çœä»½`ã€`åŸå¸‚`ã€`åˆ¶åº¦`ã€`ä¸åˆ†æ—¶ç”µä»·`ã€`å°–`ã€`å³°`ã€`å¹³`ã€`è°·`ã€`æ·±`ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨åœ¨ Tab1 ä¸­ä¸‹è½½çš„ç”µä»·è¡¨ã€‚")

    col_left, col_right = st.columns(2)

    with col_left:
        station_file = st.file_uploader("â‘  ä¸Šä¼ ç«™ç‚¹ä¿¡æ¯ Excel", type=["xlsx"], key="station_xlsx")

    with col_right:
        price_file = st.file_uploader("â‘¡ ä¸Šä¼ ç”µä»·è¡¨ Excel", type=["xlsx"], key="price_xlsx")

    c1, c2 = st.columns(2)
    with c1:
        month = st.number_input("â‘¢ é€‰æ‹©æœˆä»½", min_value=1, max_value=12, value=1, step=1)
    with c2:
        btn_calc = st.button("â–¶ å¼€å§‹è®¡ç®—ç”µè´¹", key="btn_calc_fee")

    if btn_calc:
        if station_file is None or price_file is None:
            st.error("âŒ è¯·åŒæ—¶ä¸Šä¼ ã€ç«™ç‚¹ä¿¡æ¯ Excelã€‘å’Œã€ç”µä»·è¡¨ Excelã€‘ã€‚")
        else:
            df_station = pd.read_excel(station_file)
            df_price = pd.read_excel(price_file)

            with st.spinner("æ­£åœ¨æ ¹æ®ç”µä»·è¡¨è®¡ç®—å„ç«™ç‚¹ç”µè´¹..."):
                df_out, errors = process_station_prices(df_station, df_price, month)

            st.success(f"âœ… å…±è®¡ç®— {len(df_out)} æ¡ç«™ç‚¹è®°å½•ã€‚")
            st.dataframe(df_out)

            # æœªåŒ¹é…åˆ°ç”µä»·çš„ç«™ç‚¹
            if errors:
                st.markdown("----")
                st.markdown("**âš  ä»¥ä¸‹ç«™ç‚¹æœªåŒ¹é…åˆ°ç”µä»·ï¼Œè¯·æ£€æŸ¥çœä»½ / åŸå¸‚ / é…ç½® æ˜¯å¦ä¸ç”µä»·è¡¨ä¸€è‡´ï¼š**")
                err_df = pd.DataFrame(errors, columns=["åºå·","ç«™ç‚¹åç§°","çœä»½","åŸå¸‚","é…ç½®"])
                st.dataframe(err_df)

            # ä¸‹è½½ç»“æœ
            out_bytes = BytesIO()
            df_out.to_excel(out_bytes, index=False)
            st.download_button(
                f"ğŸ“¥ ä¸‹è½½ç”µè´¹è®¡ç®—ç»“æœï¼ˆ{month}æœˆï¼‰",
                out_bytes.getvalue(),
                file_name=f"ç”µè´¹è®¡ç®—ç»“æœ_{month}æœˆ.xlsx",
                mime="application/vnd.ms-excel"
            )
    st.markdown('</div>', unsafe_allow_html=True)
